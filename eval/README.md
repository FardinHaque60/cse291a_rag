# Evaluation metrics

- files in this directory are for evaluating phase 1 and 2 performance
- In this project, the metric we used are MRR, Precision@K, Recall@K, and nDCG@K.
- to run the evaluation: ``` python evaluation.py ```
- To run the file, it need to have the label of id for the relevance chunk, relevance documents and retrieved results. 

## TODO add changes for running phase 2 pipeline, comparing metrics, running both metrics, etc.